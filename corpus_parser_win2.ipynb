{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import operator\n",
    "from collections import defaultdict,Counter\n",
    "from random import shuffle\n",
    "from pprint import pprint\n",
    "#from utils import get_files\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"INFO\")\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    \n",
    "    def __init__(self, corpus_folder=None, extn='WL2', max_files=0):\n",
    "        \n",
    "        assert corpus_folder != None, \"please specify the corpus folder\"\n",
    "        self.corpus_folder = corpus_folder\n",
    "        self.subgraph_index = 2  #########\n",
    "        self.graph_index = 0\n",
    "        self.epoch_flag = 0\n",
    "        self.max_files = max_files\n",
    "        self.graph_ids_for_batch_traversal = []\n",
    "        self.extn = extn\n",
    "\n",
    "\n",
    "    def scan_corpus(self):\n",
    "\n",
    "        subgraphs = []\n",
    "        for fname in self.graph_fname_list:\n",
    "            subgraphs.extend(\n",
    "                [l.split()[0] for l in open(fname).readlines()])  # just take the first word of every sentence\n",
    "        subgraphs.append('UNK')\n",
    "\n",
    "        subgraph_to_freq_map = Counter(subgraphs)\n",
    "        del subgraphs\n",
    "\n",
    "        subgraph_to_id_map = {sg: i for i, sg in\n",
    "                              enumerate(subgraph_to_freq_map.keys())}  # output layer of the skipgram network\n",
    "\n",
    "        self._subgraph_to_freq_map = subgraph_to_freq_map  # to be used for negative sampling\n",
    "        self._subgraph_to_id_map = subgraph_to_id_map\n",
    "        self._id_to_subgraph_map = {v:k for k,v in subgraph_to_id_map.items()}\n",
    "        self._subgraphcount = sum(subgraph_to_freq_map.values()) #total num subgraphs in all graphs\n",
    "\n",
    "        self.num_graphs = len(self.graph_fname_list) #doc size\n",
    "        self.num_subgraphs = len(subgraph_to_id_map) #vocab of word size\n",
    "\n",
    "        self.subgraph_id_freq_map_as_list = [] #id of this list is the word id and value is the freq of word with corresponding word id\n",
    "        for i in range(len(self._subgraph_to_freq_map)):\n",
    "            self.subgraph_id_freq_map_as_list.append(self._subgraph_to_freq_map[self._id_to_subgraph_map[i]])\n",
    "\n",
    "        return self._subgraph_to_id_map\n",
    "\n",
    "\n",
    "    def scan_and_load_corpus(self):\n",
    "\n",
    "        self.graph_fname_list = get_files(self.corpus_folder, extn=self.extn, max_files=self.max_files)\n",
    "        self._graph_name_to_id_map = {g: i for i, g in\n",
    "                                      enumerate(self.graph_fname_list)}  # input layer of the skipgram network\n",
    "        self._id_to_graph_name_map = {i: g for g, i in self._graph_name_to_id_map.items()}\n",
    "        subgraph_to_id_map = self.scan_corpus()\n",
    "\n",
    "        logging.info('number of graphs: %d' % self.num_graphs)\n",
    "        logging.info('subgraph vocabulary size: %d' % self.num_subgraphs)\n",
    "        logging.info('total number of subgraphs to be trained: %d' % self._subgraphcount)\n",
    "\n",
    "        self.graph_ids_for_batch_traversal = list(range(self.num_graphs))  ###########################\n",
    "        shuffle(self.graph_ids_for_batch_traversal)\n",
    "    \n",
    "    def generate_batch_from_file(self, batch_size):\n",
    "        target_subgraph_ids = []\n",
    "        context_subgraph_ids = []\n",
    "        \n",
    "        graph_name     = self.graph_fname_list[self.graph_ids_for_batch_traversal[self.graph_index]]\n",
    "        graph_contents = open(graph_name).readlines()\n",
    "        while self.subgraph_index >= len(graph_contents)-2: #####\n",
    "            self.subgraph_index = 2\n",
    "            self.graph_index += 1\n",
    "\n",
    "            if self.graph_index == len(self.graph_fname_list):   #last graph so wrap around\n",
    "                self.graph_index = 0\n",
    "                np.random.shuffle(self.graph_ids_for_batch_traversal)\n",
    "                self.epoch_flag = True\n",
    "\n",
    "            graph_name = self.graph_fname_list[self.graph_ids_for_batch_traversal[self.graph_index]]\n",
    "            graph_contents = open(graph_name).readlines()\n",
    "            \n",
    "        while len(context_subgraph_ids) < batch_size:\n",
    "\n",
    "            while self.subgraph_index >= len(graph_contents)-2: #########\n",
    "                self.subgraph_index = 2\n",
    "                self.graph_index += 1\n",
    "\n",
    "                if self.graph_index == len(self.graph_fname_list):\n",
    "                    self.graph_index = 0\n",
    "                    np.random.shuffle(self.graph_ids_for_batch_traversal)\n",
    "                    self.epoch_flag = True\n",
    "\n",
    "                graph_name = self.graph_fname_list[self.graph_ids_for_batch_traversal[self.graph_index]]\n",
    "                graph_contents = open(graph_name).readlines()\n",
    "            \n",
    "            line_id = self.subgraph_index\n",
    "            context_subgraph_1 = graph_contents[line_id].split()[0]\n",
    "            context_subgraph_0 = graph_contents[line_id-1].split()[0]\n",
    "            context_subgraph_m1 = graph_contents[line_id-2].split()[0]\n",
    "            context_subgraph_2 = graph_contents[line_id+1].split()[0]\n",
    "            context_subgraph_3 = graph_contents[line_id+2].split()[0]\n",
    "            target_graph = graph_name\n",
    "\n",
    "            context_subgraph_ids.append([self._graph_name_to_id_map[target_graph],\n",
    "                                         self._subgraph_to_id_map[context_subgraph_m1],\n",
    "                                         self._subgraph_to_id_map[context_subgraph_0],\n",
    "                                         self._subgraph_to_id_map[context_subgraph_2],\n",
    "                                         self._subgraph_to_id_map[context_subgraph_3]\n",
    "                                        ])\n",
    "            target_subgraph_ids.append(self._subgraph_to_id_map[context_subgraph_1])\n",
    "\n",
    "            self.subgraph_index += 1\n",
    "\n",
    "\n",
    "        target_subgraph_ids2 = []\n",
    "        context_subgraph_ids2 = []\n",
    "        index_shuf = list(range(len(target_subgraph_ids)))\n",
    "\n",
    "        shuffle(index_shuf)\n",
    "        for i in index_shuf:\n",
    "            target_subgraph_ids2.append(target_subgraph_ids[i])\n",
    "            context_subgraph_ids2.append(context_subgraph_ids[i])\n",
    "\n",
    "        #target_context_pairs = zip(target_graph_ids, context_subgraph_ids)\n",
    "        #shuffle(target_context_pairs)\n",
    "        #target_graph_ids, context_subgraph_ids = zip(*target_context_pairs)\n",
    "\n",
    "        target_subgraph_ids = np.array(target_subgraph_ids2, dtype=np.int32)\n",
    "        context_subgraph_ids = np.array(context_subgraph_ids2, dtype=np.int32)\n",
    "\n",
    "        targetword_outputs = np.reshape(target_subgraph_ids, [len(target_subgraph_ids), 1])\n",
    "        #contextword_outputs = np.reshape(context_subgraph_ids, [len(context_subgraph_ids), 1])\n",
    "\n",
    "        #np.savetxt(\"batch.txt\", (context_subgraph_ids, targetword_outputs), fmt=\"%d\")\n",
    "\n",
    "        return context_subgraph_ids, targetword_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
