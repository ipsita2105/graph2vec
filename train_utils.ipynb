{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ipsita/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a8d64d6af9ff>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a8d64d6af9ff>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    true_classes=batch_labels,\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os,logging\n",
    "import numpy as np\n",
    "%run corpus_parser.ipynb\n",
    "%run utils.ipynb\n",
    "%run skipgram.ipynb\n",
    "\n",
    "#from corpus_parser import Corpus\n",
    "#from utils import save_graph_embeddings\n",
    "#from skipgram import skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set it manually for now\n",
    "# corpus_dir = \"/home/ipsita/BTP/graph2vec/data/kdd_datasets/ptc\"\n",
    "# output_dir = \"/home/ipsita/BTP/graph2vec/embeddings\"\n",
    "# batch_size = 128\n",
    "# epochs = 1000\n",
    "# embedding_size = 1024\n",
    "# num_negsample = 10\n",
    "# learning_rate = 0.3\n",
    "# wlk_h = 3\n",
    "# label_filed_name = 'Label'\n",
    "# class_labels_fname = '/home/ipsita/BTP/graph2vec/data/kdd_datasets/ptc.Labels'\n",
    "\n",
    "# extn = 'g2v'+str(wlk_h)    # wlk_h is height to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ipsita/BTP/graph2vec/embeddings/ptc_dims_1024_epochs_1000_lr_0.3_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "# op_fname = '_'.join([os.path.basename(corpus_dir), 'dims', str(embedding_size), 'epochs',\n",
    "#                          str(epochs),'lr',str(learning_rate),'embeddings.txt'])\n",
    "\n",
    "# op_fname = os.path.join(output_dir, op_fname)\n",
    "\n",
    "# if os.path.isfile(op_fname):\n",
    "#     logging.info('The embedding file: {} is already present, hence NOT training skipgram model '\n",
    "#                  'for subgraph vectors'.format(op_fname))\n",
    "# print(op_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing SKIPGRAM...\n",
      "INFO:root:number of graphs: 344\n",
      "INFO:root:subgraph vocabulary size: 3804\n",
      "INFO:root:total number of subgraphs to be trained: 34837\n"
     ]
    }
   ],
   "source": [
    "# logging.info(\"Initializing SKIPGRAM...\")\n",
    "# corpus = Corpus(corpus_dir, extn = extn, max_files=0)  # just load 'max_files' files from this folder\n",
    "# corpus.scan_and_load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_skipgram = skipgram(\n",
    "#         num_graphs=corpus.num_graphs,\n",
    "#         num_subgraphs=corpus.num_subgraphs,\n",
    "#         learning_rate=learning_rate,\n",
    "#         embedding_size=embedding_size,\n",
    "#         num_negsample=num_negsample,\n",
    "#         num_steps=epochs,  # no. of time the training set will be iterated through\n",
    "#         corpus=corpus,  # data set of (target,context) tuples\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_skipgram (corpus_dir, extn, learning_rate, embedding_size, num_negsample, epochs, batch_size, output_dir):\n",
    "    '''\n",
    "\n",
    "    :param corpus_dir: folder containing WL kernel relabeled files. All the files in this folder will be relabled\n",
    "    according to WL relabeling strategy and the format of each line in these folders shall be: <target> <context 1> <context 2>....\n",
    "    :param extn: Extension of the WL relabled file\n",
    "    :param learning_rate: learning rate for the skipgram model (will involve a linear decay)\n",
    "    :param embedding_size: number of dimensions to be used for learning subgraph representations\n",
    "    :param num_negsample: number of negative samples to be used by the skipgram model\n",
    "    :param epochs: number of iterations the dataset is traversed by the skipgram model\n",
    "    :param batch_size: size of each batch for the skipgram model\n",
    "    :param output_dir: the folder where embedding file will be stored\n",
    "    :return: name of the file that contains the subgraph embeddings (in word2vec format proposed by Mikolov et al (2013))\n",
    "    '''\n",
    "\n",
    "    op_fname = '_'.join([os.path.basename(corpus_dir), 'dims', str(embedding_size), 'epochs',\n",
    "                         str(epochs),'lr',str(learning_rate),'embeddings.txt'])\n",
    "    op_fname = os.path.join(output_dir, op_fname)\n",
    "    if os.path.isfile(op_fname):\n",
    "        logging.info('The embedding file: {} is already present, hence NOT training skipgram model '\n",
    "                     'for subgraph vectors'.format(op_fname))\n",
    "        return op_fname\n",
    "\n",
    "    logging.info(\"Initializing SKIPGRAM...\")\n",
    "    corpus = Corpus(corpus_dir, extn = extn, max_files=0)  # just load 'max_files' files from this folder\n",
    "    corpus.scan_and_load_corpus()\n",
    "\n",
    "    model_skipgram = skipgram(\n",
    "        num_graphs=corpus.num_graphs,\n",
    "        num_subgraphs=corpus.num_subgraphs,\n",
    "        learning_rate=learning_rate,\n",
    "        embedding_size=embedding_size,\n",
    "        num_negsample=num_negsample,\n",
    "        num_steps=epochs,  # no. of time the training set will be iterated through\n",
    "        corpus=corpus,  # data set of (target,context) tuples\n",
    "    )\n",
    "\n",
    "    final_embeddings = model_skipgram.train(corpus=corpus,batch_size=batch_size)\n",
    "\n",
    "    logging.info('Write the matrix to a word2vec format file')\n",
    "    save_graph_embeddings(corpus, final_embeddings, op_fname)\n",
    "    logging.info('Completed writing the final embeddings, pls check file: {} for the same'.format(op_fname))\n",
    "    return op_fname\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
